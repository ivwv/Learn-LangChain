# 📘 第05课 — 嵌入和向量存储基础 (RAG 的基石)

本课程将介绍 RAG (Retrieval-Augmented Generation，检索增强生成) 所需的第一个主要概念：
**嵌入 (Embeddings) + 向量搜索 (Vector Search)。**

在这里，我们将学习如何将文本转换为数值向量，存储它们，并执行相似性搜索。

这是现代 AI 中最重要的概念之一。

---

# 🚀 本课将做什么 (流程概述)

1️⃣ 加载嵌入模型
2️⃣ 将文本转换为嵌入
3️⃣ 将嵌入存储在**向量存储**中
4️⃣ 执行**相似性搜索**
5️⃣ 检索最相关的文档

这正是以下技术的基础：

- **ChatGPT 内存**
- **AI 搜索引擎**
- **RAG 聊天机器人**
- **多智能体知识检索**
- **智能文档问答系统**

---

# 🔁 流程图 (简化)

```
文本文档
        │
        ▼
  嵌入模型
   (文本 → 向量数字)
        │
        ▼
   向量存储
  (内存或数据库)
        │
        ▼
用户查询
        │
        ▼
查询嵌入 (向量)
        │
        ▼
相似性搜索 (余弦距离)
        │
        ▼
最匹配的文档
```

---

# 🧠 代码按逻辑块解释

---

## 🔹 **1. 设置 + 导入所需组件**

这部分加载：

- dotenv (环境变量)
- Google Gemini 嵌入模型
- 内存向量存储

目的：
准备嵌入文本和存储向量所需的工具。

---

## 🔹 **2. 初始化嵌入模型**

您将使用以下内容创建嵌入生成器：

- Gemini 模型：`"text-embedding-004"`
- 来自 `.env` 的 API 密钥

目的：
将文本转换为数值向量（由 768-1536 个浮点数组成的数组）。

嵌入允许语义理解：
“Paresh 的年龄？”与“Paresh 20 岁。”是相似的。

---

## 🔹 **3. 创建内存向量存储**

`MemoryVectorStore` 将所有向量存储在 RAM 中。

优点：

- 快速
- 无需数据库
- 非常适合学习和测试
- 功能与 Pinecone / Qdrant 完全相同，但运行在本地

此存储允许基于向量距离进行相似性搜索。

---

## 🔹 **4. 将文档添加到向量存储**

我们插入多个文本文档，例如：

- “Paresh 正在构建一个智能体 AI 后端…”
- “Paresh 20 岁。”

当您添加文档时：

1. 它会嵌入每个文本
2. 将所有嵌入存储在向量存储中
3. 维护内部映射 (文档 → 向量)

现在存储知道每个文档的**语义含义**。

---

## 🔹 **5. 执行相似性搜索**

查询：

```
"用户年龄 ?"
```

幕后步骤：

1. 查询被嵌入
2. 存储将查询向量与所有存储的向量进行比较
3. 测量接近度（余弦相似度）
4. 返回最匹配的文档

您将获得类似以下的结果：

- (可能) “Paresh 20 岁。”
- (可能) 任何与 Paresh 信息相关的内容

这是一种**语义搜索**——而非关键词匹配。

---

# 🧩 为什么本课很重要

嵌入在每个高级 AI 应用中都有使用：

### ✔ RAG (检索增强生成)
在回答之前，使用向量搜索为模型提供正确的上下文。

### ✔ 多智能体系统
智能体在推理之前检索相关记忆。

### ✔ AI 搜索引擎
按含义搜索，而不是关键词。

### ✔ 聊天机器人内存
将过去的对话存储为嵌入，并查找相关的历史记录。

### ✔ 文档问答
附带 PDF、DOC、网站——语义提取信息。

本课是以后所有内容**核心**。

---

# 🌍 实际应用场景

- “给我关于第五章的笔记” → 语义检索
- 能够记住用户以前信息的聊天机器人
- 在回答之前获取事实的 AI
- OpenAI RAG 教程中使用的检索管道
- 电子商务语义搜索（“2000 卢比以下的红色跑步鞋”）
- 简历匹配
- FAQ 问答机器人

---

# ▶️ 如何运行

```
node 05-embeddings-vector.js
```

请确保您的 `.env` 文件包含：

```
GEMINI_API_KEY=your_api_key_here
```

---

# ⭐ 下一章
**第06课 — 基本 RAG (使用嵌入 + 向量存储 + LLM 回答用户查询)。**
