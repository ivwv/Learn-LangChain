# ğŸ“˜ Lesson 04 â€” Adding Custom Preprocessing Steps to Your Chain

In this lesson, we learn how to integrate **custom logic** into a LangChain pipeline before the LLM is executed.  
This is extremely useful when you need to:

- Clean or normalize input  
- Validate data  
- Transform user queries  
- Add metadata  
- Prepare context  
- Call extra functions/tools before the model runs  

This pattern is used heavily in real-world AI applications, especially in agents, chatbots, and APIs.

---

# ğŸš€ What We Will Do in This Lesson (Flow Overview)

This chapter introduces a new concept:  
ğŸ‘‰ **A custom step that runs BEFORE prompt â†’ model â†’ parser.**

Our flow becomes:

```
Input
  â†“
Custom Preprocessing Step (normalize / validate / transform)
  â†“
PromptTemplate (fills {topic})
  â†“
Gemini LLM (generates answer)
  â†“
StringOutputParser (clean string output)
  â†“
Final text response
```

This gives us **full control** over the input before it hits the LLM.

---

# ğŸ§  Why Custom Steps Matter

Real projects require much more than just sending raw user text to a model.

For example, you may need to:

- Trim bad whitespace  
- Convert to lowercase  
- Check if input is valid  
- Add default values  
- Sanitize user data  
- Pre-process JSON  
- Pre-extract keywords  
- Call external tools (database, search API, etc.)  
- Log inputs  
- Modify state inside multi-agent workflows  

This lesson shows the **foundation of how to do all of that.**

---

# ğŸ”§ Breakdown of Logical Blocks

---

## ğŸ”¹ **1. Setup & Model + Prompt + Parser**

We initialize:

- the Gemini LLM  
- the prompt  
- the parser  

This part is identical to previous lessons, but now the chain will be wrapped inside a custom function.

Purpose of these components:

- **PromptTemplate** â†’ formats the question  
- **Model** â†’ generates output  
- **Parser** â†’ returns simple text  

They are the core of the chain.

---

## ğŸ”¹ **2. Custom Preprocessing Step (The New Concept)**

Inside the `runChain()` function, we add:

- extra logic  
- transformations  
- validation  
- tools  
- preprocessing  

Example used here:

- Trim extra spaces  
- Convert the topic to lowercase  
- Spread input for flexibility  

This acts as a **â€œmiddlewareâ€** before the AI runs.

---

## ğŸ”¹ **3. Build + Invoke the Chain Dynamically**

Instead of creating a chain once, we build it inside the function:

```
prompt â†’ model â†’ parser
```

Then we call `.invoke()` with the **normalized** input.

This pattern allows you to:

- plug multiple tools  
- add different models  
- inject dynamic logic  
- add state-aware preprocessing  

This structure is common in production agent systems.

---

## ğŸ”¹ **4. Return the Final Clean Output**

After the LLM runs, the parser gives you back a **pure string**, which is perfect for:

- REST responses  
- Socket.io responses  
- UI output  
- Database logs  

Your final output is clean and ready to use.

---

# ğŸ” Flow Diagram (Simplified)

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  User Input (topic)     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Custom Preprocessing     â”‚
          â”‚ (trim, lowercase, etc.) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Prompt Template          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Gemini 2.0 Flash (LLM)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ String Output Parser     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Final Clean Text Output â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸŒ Real-World Use Cases

This pattern is used in:

### âœ” AI Chatbots  
Normalize user input before sending to LLM.

### âœ” Agent Systems  
Add search results, database values, or API data before generating answers.

### âœ” RAG  
Embed â†’ retrieve â†’ preprocess â†’ send to prompt â†’ LLM.

### âœ” AI Automations  
Modify user query, add defaults, detect intent.

### âœ” APIs  
Validate payload before processing.

### âœ” Educational or explanation systems  
Convert user text into a clean format before prompting.

---

# â­ Why This Lesson Is Important

You have now learned the **most important skill** for building real AI apps:

### ğŸ”¥ How to add custom logic BEFORE the LLM.

This is what separates â€œtoy examplesâ€ from **production-grade AI pipelines**.

Nearly every advanced feature youâ€™ll build later depends on this:

- Tools  
- Agents  
- Memory  
- Multi-agent orchestration  
- LangGraph nodes  
- Context injection  
- RAG retrieval  
- Input validation  
- Pre/post-processing  

---

# â–¶ï¸ Next Chapter  
**Lesson 05 â€” Embeddings & Vector Basics (Turning text into numbers for search + RAG).**

