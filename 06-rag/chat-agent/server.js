import express from "express";
import cors from "cors";
import { config } from "dotenv";
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { Chroma } from "@langchain/community/vectorstores/chroma";
import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { Document } from "@langchain/core/documents";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// åŠ è½½ .env
config({ path: path.join(__dirname, "../../.env") });

const app = express();
app.use(cors());
app.use(express.json());

// 1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
const embeddings = new OpenAIEmbeddings({
  model: "qwen3-embedding:4b", // è¯·ç¡®ä¿è¿™æ˜¯ä½ ollamaä¸­çœŸå®å­˜åœ¨çš„æ¨¡å‹å
  configuration: {
    baseURL: process.env.OLLAMA_BASE_URL,
  },
});

// 2. åˆå§‹åŒ– LLM
const model = new ChatOpenAI({
  // model: "gpt-4o",
  // temperature: 0.7, // ç¨å¾®å¢åŠ ä¸€ç‚¹éšæœºæ€§ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
  model: "gpt-4o",
  temperature: 0.7, // ç¨å¾®å¢åŠ ä¸€ç‚¹éšæœºæ€§ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
  configuration: {
    // baseURL: process.env.OLLAMA_BASE_URL,
  },
});

const collectionName = "multi-category-kb-v5";
let vectorStore;

// --- åˆå§‹åŒ–å‘é‡æ•°æ®åº“é€»è¾‘ä¿æŒä¸å˜ ---
async function initVectorStore() {
  vectorStore = await Chroma.fromExistingCollection(embeddings, {
    collectionName: collectionName,
    url: "http://192.168.0.99:8300",
  });

  const count = await vectorStore.collection.count();
  if (count === 0) {
    console.log("æ£€æµ‹åˆ°æ•°æ®åº“ä¸ºç©ºï¼Œæ­£åœ¨åŠ è½½çŸ¥è¯†åº“æ–‡ä»¶...");
    const dataDir = path.join(__dirname, "../data");

    if (fs.existsSync(dataDir)) {
      const files = fs.readdirSync(dataDir).filter((f) => f.endsWith(".md"));
      const docs = [];

      for (const file of files) {
        const filePath = path.join(dataDir, file);
        const content = fs.readFileSync(filePath, "utf-8");
        const sections = content.split("======").filter((s) => s.trim() !== "");

        sections.forEach((section) => {
          const trimmedSection = section.trim();
          const lines = trimmedSection.split("\n");
          const firstLine = lines[0] || "";
          const titleMatch = firstLine.match(/^##\s+(.*)/);
          const title = titleMatch ? titleMatch[1].trim() : "æœªå‘½åçŸ¥è¯†ç‚¹";

          docs.push(
            new Document({
              pageContent: trimmedSection,
              metadata: {
                source: file,
                title: title,
                category: file.replace(".md", ""),
              },
            })
          );
        });
      }

      if (docs.length > 0) {
        console.log(`å‡†å¤‡å…¥åº“ ${docs.length} æ¡æ–‡æ¡£...`);
        const chunkSize = 50;
        for (let i = 0; i < docs.length; i += chunkSize) {
          const chunk = docs.slice(i, i + chunkSize);
          await vectorStore.addDocuments(chunk);
        }
        console.log("ğŸ‰ æ•°æ®å…¥åº“å®Œæˆ");
      }
    }
  } else {
    console.log(`ğŸ“Š æ•°æ®åº“ [${collectionName}] ä¸­å·²å­˜åœ¨ ${count} æ¡è®°å½•ã€‚`);
  }
}

// æ¨¡æ‹Ÿå†…å­˜å¯¹è¯å†å²
const historyMap = new Map();

// --- æ ¸å¿ƒä¿®æ”¹ï¼šæµå¼æ¥å£ ---
app.post("/api/chat/stream", async (req, res) => {
  const { sessionId, question } = req.body;

  // 1. è®¾ç½® SSE å“åº”å¤´
  res.setHeader("Content-Type", "text/event-stream; charset=utf-8");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");

  if (!sessionId || !question) {
    res.write(`data: ${JSON.stringify({ error: "Missing sessionId or question" })}\n\n`);
    res.end();
    return;
  }

  try {
    let history = historyMap.get(sessionId) || [];

    // 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    const similarDocs = await vectorStore.similaritySearch(question, 3);
    const context = similarDocs.map((d) => d.pageContent).join("\n");

    // æå–æ¥æºå¹¶å»é‡
    const sourceList = similarDocs.map((d) => `[${d.metadata.source}] ${d.metadata.title}`);
    const uniqueSources = [...new Set(sourceList)];

    // 3. ç«‹å³å‘å®¢æˆ·ç«¯å‘é€æ¥æºä¿¡æ¯ (Type: sources)
    res.write(`data: ${JSON.stringify({ type: "sources", data: uniqueSources })}\n\n`);

    // æ„å»º Prompt
    const historyText = history
      .slice(-6) // å–æœ€è¿‘6æ¡
      .map((h) => `${h.role === "user" ? "ç”¨æˆ·" : "åŠ©æ‰‹"}: ${h.content}`)
      .join("\n");

    const promptTemplate = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“åŠ©æ‰‹ã€‚è¯·ç»“åˆå¯¹è¯å†å²å’Œæä¾›çš„ä¸Šä¸‹æ–‡å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¯¹è¯å†å²:
{history}

ä¸Šä¸‹æ–‡å†…å®¹:
{context}

å½“å‰é—®é¢˜:
{question}

å›ç­”:`;

    const prompt = PromptTemplate.fromTemplate(promptTemplate);
    const chain = prompt.pipe(model).pipe(new StringOutputParser());

    // 4. å¼€å¯æµå¼ç”Ÿæˆ
    const stream = await chain.stream({
      history: historyText || "æ— å†å²è®°å½•",
      context: context || "æ— ç›¸å…³ä¸Šä¸‹æ–‡",
      question,
    });

    let fullAnswer = "";

    // 5. å¾ªç¯æ¨é€æ•°æ®å— (Type: content)
    for await (const chunk of stream) {
      fullAnswer += chunk;
      // SSE æ ¼å¼: data: {json}\n\n
      res.write(`data: ${JSON.stringify({ type: "content", data: chunk })}\n\n`);
    }

    // 6. æ›´æ–°å†å²è®°å½• (åªæœ‰åœ¨ç”Ÿæˆå®Œæˆåæ‰ä¿å­˜ï¼Œä¿è¯å†å²è®°å½•å®Œæ•´)
    history.push({ role: "user", content: question });
    history.push({ role: "assistant", content: fullAnswer });

    // é™åˆ¶å†å²é•¿åº¦
    if (history.length > 10) history = history.slice(-10);
    historyMap.set(sessionId, history);

    // å‘é€ç»“æŸä¿¡å· (Type: done)
    res.write(`data: ${JSON.stringify({ type: "done" })}\n\n`);
    res.end();
  } catch (error) {
    console.error("Chat Error:", error);
    res.write(`data: ${JSON.stringify({ error: "Internal Server Error" })}\n\n`);
    res.end();
  }
});

const PORT = 3000;
initVectorStore()
  .then(() => {
    app.listen(PORT, () => {
      console.log(`Server is running on http://localhost:${PORT}`);
    });
  })
  .catch((err) => {
    console.error("Failed to initialize vector store:", err);
  });
