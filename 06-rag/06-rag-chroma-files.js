import { config } from "dotenv";
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { Chroma } from "@langchain/community/vectorstores/chroma";
import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { Document } from "@langchain/core/documents";
import fs from "fs";
import path from "path";

config();

// 1ï¸âƒ£ åˆå§‹åŒ–åµŒå…¥æ¨¡åž‹
const embeddings = new OpenAIEmbeddings({
  model: "qwen3-embedding:4b",
  configuration: {
    baseURL: process.env.OLLAMA_BASE_URL,
  },
});

// 2ï¸âƒ£ åˆå§‹åŒ– LLM
const model = new ChatOpenAI({
  model: "gpt-4", // ä¿®æ”¹ä¸ºæ›´å¸¸ç”¨çš„æ¨¡åž‹åç§°
});

async function main() {
  // 3ï¸âƒ£ è¿žæŽ¥åˆ° Chroma å‘é‡æ•°æ®åº“
  const vectorStore = await Chroma.fromExistingCollection(embeddings, {
    collectionName: "tech-knowledge-base-v2", // ä½¿ç”¨æ–°é›†åˆé¿å…å†²çª
    url: "http://192.168.0.99:8300",
  });

  // 4ï¸âƒ£ ä»Žæ–‡ä»¶è¯»å–æ•°æ®å¹¶å¡«å…… (ä»…åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæˆ–éœ€è¦æ›´æ–°æ—¶æ‰§è¡Œ)
  const count = await vectorStore.collection.count();
  if (count === 0) {
    console.log("æ£€æµ‹åˆ°æ•°æ®åº“ä¸ºç©ºï¼Œæ­£åœ¨ä»Žæ–‡ä»¶åˆå§‹åŒ–æ•°æ®...");

    const dataDir = path.join(process.cwd(), "06-rag/data");
    const files = fs.readdirSync(dataDir);
    const docs = [];

    for (const file of files) {
      if (file.endsWith(".txt")) {
        const filePath = path.join(dataDir, file);
        const content = fs.readFileSync(filePath, "utf-8");

        // æŒ‰è¡Œæ‹†åˆ†ç®€å•çš„ç¤ºä¾‹æ–‡æ¡£
        const lines = content.split("\n").filter((line) => line.trim() !== "");

        lines.forEach((line) => {
          docs.push(
            new Document({
              pageContent: line,
              metadata: {
                source: file, // è®°å½•æ–‡ä»¶ååˆ° metadata
                category: "knowledge-base",
              },
            })
          );
        });
      }
    }

    if (docs.length > 0) {
      await vectorStore.addDocuments(docs);
      console.log(`âœ… æ•°æ®å…¥åº“å®Œæˆï¼Œå…± ${docs.length} æ¡è®°å½•`);
    }
  } else {
    console.log(`ðŸ“Š æ•°æ®åº“ä¸­å·²å­˜åœ¨ ${count} æ¡è®°å½•ã€‚`);
  }

  // 5ï¸âƒ£ æ‰§è¡Œæœç´¢
  const question = "å¦‚ä½•å®žçŽ°å•ç‚¹ç™»å½• SSO";
  const similarDocs = await vectorStore.similaritySearch(question, 3);

  // 6ï¸âƒ£ è¾“å‡ºå¼•ç”¨çš„çŸ¥è¯†åº“æ–‡ä»¶
  console.log("ðŸ” æ£€ç´¢åˆ°çš„å¼•ç”¨æ¥æº:");
  const sources = similarDocs.map((d) => d.metadata.source);
  const uniqueSources = [...new Set(sources)];
  uniqueSources.forEach((source) => console.log(`- [æ–‡ä»¶]: ${source}`));

  // 7ï¸âƒ£ æž„å»º RAG é“¾
  const context = similarDocs.map((d) => d.pageContent).join("\n");
  const prompt = PromptTemplate.fromTemplate(`ä½¿ç”¨ä¸Šä¸‹æ–‡å›žç­”é—®é¢˜ã€‚

CONTEXT:
{context}

QUESTION:
{question}

ANSWER:`);

  const chain = prompt.pipe(model).pipe(new StringOutputParser());
  const answer = await chain.invoke({ context, question });

  console.log("ðŸ“Œ AI ç­”æ¡ˆ:", answer);
}

main().catch(console.error);
