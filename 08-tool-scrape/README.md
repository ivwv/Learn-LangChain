# ğŸ“˜ Lesson 08 â€” Web Scraper Tool (with RunnableLambda + Zod Validation)

In this lesson, we build a **real production-grade tool**:  
A **Website Scraper Tool** that fetches a webpage, cleans it, and returns readable text.

This tool will later be used by agents to:

- read websites  
- answer questions from URLs  
- automate research  
- do Perplexity-style multi-tool workflows  

The README explains each code block **in the exact same sequence as your code**.

---

# ğŸš€ What We Build in This Lesson (Flow Overview)

1ï¸âƒ£ Validate the input (URL) using Zod  
2ï¸âƒ£ Create a scraper tool using RunnableLambda  
3ï¸âƒ£ Fetch the website  
4ï¸âƒ£ Strip HTML tags, scripts, styles  
5ï¸âƒ£ Return clean, readable text  
6ï¸âƒ£ Test the tool using `.invoke()`  

This is a **real, useful** tool â€” not a toy example.

---

# ğŸ” Flow Diagram (Simple)

```
User sends URL
      â†“
Zod Validation (checks URL format)
      â†“
Fetch webpage HTML
      â†“
Remove <script>, <style>, HTML tags
      â†“
Clean + Normalize Text
      â†“
Return structured result { success, content }
```

---

# ğŸ§© **Code Explanation (Block-by-Block, EXACT CODE ORDER)**

---

## ğŸ”¹ **BLOCK 1 â€” Import RunnableLambda + Zod**

```js
import { RunnableLambda } from "@langchain/core/runnables";
import { z } from "zod";
```

### âœ” Explanation:
- `RunnableLambda` â†’ converts any JS function into a LangChain tool  
- `zod` â†’ validates input (we ensure `url` is a valid URL)

Using Zod is **production best practice**:
- prevents errors  
- prevents injection attacks  
- ensures tool receives correct parameters  

---

## ğŸ”¹ **BLOCK 2 â€” Create Zod Schema for Input Validation**

```js
const schema = z.object({
  url: z.string().url(),
});
```

### âœ” Explanation:
We define what valid input should look like:

- Input must be an object  
- It must contain a `url` field  
- That field must be a valid URL  

If the user (or LLM) sends bad input â†’  
the schema throws a clean, helpful error.

---

## ğŸ”¹ **BLOCK 3 â€” Create the Web Scraping Tool**

```js
export const scrapeWebsite = RunnableLambda.from(async (input) => {
  const { url } = schema.parse(input);
```

### âœ” Explanation:
- Wrap our function with RunnableLambda â†’ becomes a LangChain tool  
- First step: validate the user input using Zod (`schema.parse()`)

If the input is invalid â†’ function stops immediately.  
If valid â†’ we continue.

---

## ğŸ”¹ **BLOCK 4 â€” Fetch the Website**

```js
const res = await fetch(url);

if (!res.ok) {
  return {
    success: false,
    error: `Failed to fetch URL. Status: ${res.status}`
  };
}
```

### âœ” Explanation:
We make an HTTP request to the given URL.

- If site is down â†’ return `{success:false}`  
- If page doesn't exist â†’ return error  
- No crashing or unhandled exceptions  

This makes the scraper **safe** and **reliable**.

---

## ğŸ”¹ **BLOCK 5 â€” Read HTML**

```js
const html = await res.text();
```

### âœ” Explanation:
We extract the raw HTML of the webpage.

Example:

```
<html>
  <head>...</head>
  <body>Hello</body>
</html>
```

We will clean it next.

---

## ğŸ”¹ **BLOCK 6 â€” Clean the HTML and Extract Plain Text**

```js
const text = html
  .replace(/<script[\s\S]*?<\/script>/gi, "")
  .replace(/<style[\s\S]*?<\/style>/gi, "")
  .replace(/<[^>]+>/g, " ")
  .replace(/\s+/g, " ")
  .trim();
```

### âœ” Explanation:

This block removes:

- `<script> ... </script>`  
- `<style> ... </style>`  
- All HTML tags `<div>`, `<h1>`, `<p>`  
- Extra spaces  
- Newlines  
- Whitespace noise  

Result = **clean readable text**, perfect for passing to an LLM.

Example:

```
"Welcome to my website This is the home page"
```

This is EXACTLY how Perplexity, GPT-browser tools, and research agents work.

---

## ğŸ”¹ **BLOCK 7 â€” Return a Structured Response**

```js
return {
  success: true,
  url,
  content: text.slice(0, 3000),
};
```

### âœ” Explanation:
We return a JSON result with:

- `success` â†’ true  
- `url` â†’ the URL scraped  
- `content` â†’ first 3000 chars of cleaned text  

Why 3000?

- Prevents overloading LLM  
- Keeps responses fast  
- Works well with Perplexity-style agents  

---

## ğŸ”¹ **BLOCK 8 â€” Error Handling (Fail-Safe)**

```js
} catch (err) {
  return {
    success: false,
    error: err.message,
  };
}
```

### âœ” Explanation:
If fetch crashes or URL is invalid â†’  
we catch the error and return a **clean**, LLM-friendly error object.

This prevents agent crashes.

---

## ğŸ”¹ **BLOCK 9 â€” Testing the Tool**

```js
const result = await scrapeWebsite.invoke({
  url: "https://webreal.in",
});
console.log(result);
```

### âœ” Explanation:
We test our tool by scraping `webreal.in`.

`.invoke()` is the universal LangChain execution method.

Result printed will look like:

```
{
  success: true,
  url: "...",
  content: "clean scraped text..."
}
```

---

# ğŸŒ Real-World Use Cases

This tool is the foundation of:

### âœ” Perplexity-style web research agents  
### âœ” Multi-agent research flows  
### âœ” Site QA bots  
### âœ” SEO analyzers  
### âœ” News scrapers  
### âœ” Competitor analysis bots  
### âœ” Auto-summary pipelines  
### âœ” Fact-checking agents  

You will later plug this scraper into an **agent with reasoning**, and it will automatically:

- decide which URL to scrape  
- scrape it  
- read content  
- answer using RAG  

---

# â–¶ï¸ How to Run

```
node 08-tool-scrape.js
```

---

# â­ Next Chapter  
**Lesson 09 â€” Using an LLM as a Tool (AI calling another AI).**

