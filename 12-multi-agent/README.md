# ğŸ“˜ Lesson 12 â€” Multi-Agent System (Planner â†’ Scrape/Search â†’ Summarize)

This lesson teaches how to build your **first multi-agent system** using LangGraph.

You will create:

1ï¸âƒ£ A **PLANNER AGENT** â†’ decides which tool to use  
2ï¸âƒ£ A **SCRAPER AGENT** â†’ fetches website text  
3ï¸âƒ£ A **SEARCH AGENT** â†’ returns fake search data  
4ï¸âƒ£ A **SUMMARIZER AGENT** â†’ creates the final answer  

This is EXACTLY how large agentic systems work:

- Perplexity  
- Devin / OpenDevin  
- AutoGPT  
- CrewAI  
- LangGraph agents  

Each â€œagentâ€ = one node, one responsibility.

---

# ğŸ”¥ Full Flow Diagram (Matches Code)

```
START
  â†“
[ PLAN ]
  â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â†“              â†“              â†“
SCRAPE       SEARCH       SUMMARIZE (direct)
  â†“              â†“
       SUMMARIZE
            â†“
           END
```

---

# ğŸ§© BLOCK-BY-BLOCK EXPLANATION (WITH CODE)

---

## ğŸ”¹ BLOCK 1 â€” dotenv Setup & Imports

```js
import { config } from "dotenv";
config();

import { ChatOpenAI } from "@langchain/openai";
import {
  MessagesAnnotation,
  StateGraph,
  START,
  END,
} from "@langchain/langgraph";
```

### âœ” Explanation  
- Loads environment variables  
- Imports **GPT-4o-mini** and all LangGraph components  
- These are mandatory for multi-node agent workflows  

---

## ğŸ”¹ BLOCK 2 â€” The Model (LLM for Planner + Summary)

```js
const model = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
});
```

### âœ” Explanation  
- Fast & predictable model  
- Used for **planning decisions** and **summary generation**  
- Temperature 0 = no randomness  

---

## ğŸ”¹ BLOCK 3 â€” FAKE SEARCH TOOL (Demo Only)

```js
async function fakeSearch(query) {
  return `Search results for: ${query}
1) Google 2023 revenue was $307B.
2) Alphabet grew 9%.
(FAKE DEMO DATA)
`;
}
```

### âœ” Explanation  
- Pretend search engine  
- In real agent: replace with Tavily, Bing, SerpAPI, etc.  
- Helps the Planner choose **search** when user asks factual queries  

---

## ğŸ”¹ BLOCK 4 â€” SCRAPER TOOL

```js
async function scrapeWebsite(url) {
  try {
    const res = await fetch(url);
    const html = await res.text();
    return html.replace(/<[^>]+>/g, " ").trim().slice(0, 1500);
  } catch {
    return "Error scraping";
  }
}
```

### âœ” Explanation  
- Fetch URL  
- Remove HTML tags  
- Clean text  
- Limit to 1500 chars  
- Used when Planner chooses `"scrape"`  

---

## ğŸ”¹ BLOCK 5 â€” NODE 1: PLANNER AGENT  
Decides which tool to use: **scrape | search | math | summarize**

```js
async function plannerNode(state) {
  const decision = await model.invoke([
    {
      role: "system",
      content:
        "You are a tool-decider. Output ONLY one of these words: scrape, search, math, summarize.",
    },
    ...state.messages,
  ]);

  const mode = decision.content.trim().toLowerCase();

  return {
    messages: [
      ...state.messages,
      { role: "system", content: `PLAN=${mode}` },
    ],
  };
}
```

### âœ” Explanation  
- Takes the user message  
- LLM decides the required action  
- Stores the plan as:  
  ```
  PLAN=search
  ```  

This is the **Supervisor Agent**.

---

## ğŸ”¹ BLOCK 6 â€” NODE 2: SCRAPE AGENT

```js
async function scrapeNode(state) {
  const last = state.messages.at(-1).content;
  const url = last.match(/https?:\/\/\S+/)?.[0];

  const text = await scrapeWebsite(url);

  return {
    messages: [
      ...state.messages,
      { role: "system", content: `SCRAPED=${text}` },
    ],
  };
}
```

### âœ” Explanation  
- Extracts URL from last message  
- Calls scraper tool  
- Saves scraped text to state  

---

## ğŸ”¹ BLOCK 7 â€” NODE 3: SEARCH AGENT

```js
async function searchNode(state) {
  const lastUser = state.messages.find((m) => m.role === "user")?.content;
  const result = await fakeSearch(lastUser);

  return {
    messages: [
      ...state.messages,
      { role: "system", content: `SEARCHED=${result}` },
    ],
  };
}
```

### âœ” Explanation  
- Takes **original user query**  
- Runs fake search  
- Saves search results  
- Very similar to Perplexityâ€™s search tool  

---

## ğŸ”¹ BLOCK 8 â€” NODE 4: SUMMARIZER AGENT  
Combines final tool output into clean summary.

```js
async function summarizeNode(state) {
  const data = state.messages.find((m) =>
    m.content.startsWith("SCRAPED=") || m.content.startsWith("SEARCHED=")
  )?.content.replace("SCRAPED=", "").replace("SEARCHED=", "");

  const summary = await model.invoke([
    { role: "user", content: `Summarize:\n${data}` },
  ]);

  return {
    messages: [...state.messages, { role: "assistant", content: summary.content }],
  };
}
```

### âœ” Explanation  
- Reads output of **scrape** or **search**  
- Asks LLM to produce structured summary  
- Adds **final assistant message**  

---

## ğŸ”¹ BLOCK 9 â€” BUILD THE MULTI-AGENT GRAPH

```js
const graph = new StateGraph(MessagesAnnotation)
  .addNode("plan", plannerNode)
  .addNode("scrape", scrapeNode)
  .addNode("search", searchNode)
  .addNode("summarize", summarizeNode);
```

### âœ” Explanation  
You register all agents/nodes:

```
plan â†’ scrape â†’ search â†’ summarize
```

This is your multi-agent "company."

---

## ğŸ”¹ BLOCK 10 â€” FLOW LOGIC (Conditional Routing)

```js
graph.addEdge(START, "plan");

graph.addConditionalEdges("plan", (state) => {
  const last = state.messages.at(-1).content;
  if (last.includes("scrape")) return "scrape";
  if (last.includes("search")) return "search";
  if (last.includes("summarize")) return "summarize";
  return END;
});

graph.addEdge("scrape", "summarize");
graph.addEdge("search", "summarize");
graph.addEdge("summarize", END);
```

### âœ” Explanation  
- Start â†’ Planner  
- Planner decides which tool node runs  
- scrape â†’ summarize  
- search â†’ summarize  
- summarize â†’ END  

This is real **tool decision-making**.

---

## ğŸ”¹ BLOCK 11 â€” Compile the Agent

```js
const agent = graph.compile();
```

### âœ” Explanation  
Turns the graph into a runnable multi-agent workflow.

---

## ğŸ”¹ BLOCK 12 â€” RUN THE AGENT

```js
const result = await agent.invoke({
  messages: [
    { role: "user", content: "Find Google 2023 revenue" },
  ],
});
```

### âœ” Explanation  
- User query triggers Planner  
- Planner sees it's a **search query**  
- Runs **fakeSearch**  
- Then **summarize**  
- Outputs final assistant answer  

---

## ğŸ”¹ BLOCK 13 â€” Print Final Output

```js
console.log(result.messages.at(-1).content);
```

---

# ğŸ“Œ EXPECTED OUTPUT (Example)

```
â€¢ Googleâ€™s 2023 revenue was approximately $307B.
â€¢ Alphabetâ€™s revenue saw a growth of 9%.
â€¢ These numbers are retrieved from the fake search tool.
â€¢ Shows annual performance metrics of Google/Alphabet.
â€¢ Summary generated by AI from search results.
```

---

# â–¶ï¸ HOW TO RUN

```
node 12-multi-agent.js
```

Ensure `.env` contains:

```
OPENAI_API_KEY=your_key_here
```

---

# ğŸŒ REAL-WORLD USE CASES

This architecture is used in:

### âœ” Perplexity AI  
### âœ” Multi-agent research assistants  
### âœ” Auto-analysts (SEO, finance, marketing)  
### âœ” AI browser tools  
### âœ” Data extraction + summary systems  
### âœ” Supervisor â†’ Worker agent systems  
### âœ” RAG + Agents combined  

---

# â­ Next Lesson  
**Lesson 13 â€” Multi-Agent System (Advanced Version: Real Tools + Branching + Dynamic Reasoning).**
