# ðŸ“˜ Lesson 13 â€” Production-Grade Multi-Agent System  
### (Real Scraping â€¢ Real Search â€¢ Hard Routing â€¢ REPL Chat â€¢ Zod Schema)

This is the most **real-world**, **production-level**, and **feature-rich** agent in the entire repository.

Lesson 13 shows how to build **Perplexity-style agents**, using:

- **Real Browser Scraping (Puppeteer)**
- **Real Web Search (Tavily API)**
- **Hard + LLM Routing**
- **Zod for Schema Validation**
- **LangGraph State Machines**
- **REPL terminal chat**

This is NOT a demo.  
This is a template you can use for startups and production AI.

---

# ðŸ§± Why This Lesson Exists

Lessons 11 â†’ 12 taught you the basics of agent workflow.

Lesson 13 is where it becomes **real**:

- Real search  
- Real scraping  
- Real routing  
- Real error-handling  
- Real message schemas  
- Real agent lifecycle  

This is the point where your agent becomes **useful**, not just â€œcool code.â€

---

# ðŸ“¦ Packages Used (And WHY)

| Package | Why we need it |
|---------|----------------|
| **@langchain/langgraph** | Build multi-node agent workflows |
| **@langchain/openai** | Use GPT-4o-mini reliably for routing + summarization |
| **puppeteer** | **Real browser scraping**, unlike regex scraping |
| **zod** | Validate agent state & prevent broken messages |
| **dotenv** | Store API keys (OPENAI, TAVILY) |
| **Tavily API** | **Real internet search** with factual answers |
| **readline** | Interactive REPL (terminal chat) |

---

# ðŸ¤– Why Use OpenAI Instead of Gemini Here?

Great question.

Gemini is amazing, but:

### âœ” OpenAI GPT-4o-mini is:
- Faster
- Cheaper
- More deterministic
- Better at **short routing decisions**
- More reliable with â€œSTRICT router instructionsâ€

### âœ” LangGraphâ€™s official examples use OpenAI  
So compatibility is perfect.

### âœ” Tavily recommends OpenAI for search â†’ answer use cases

You **can** swap in Gemini later.  
But for Lesson 13, OpenAI is the safest + most stable choice.

---

# ðŸ”¥ ARCHITECTURE (In One Diagram)

```
User Input
     â†“
[ PLAN NODE ]
   - Hard rule: URL â†’ SCRAPE
   - Else: LLM decides SEARCH or ANSWER
     â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â†“            â†“            â†“
SCRAPE      SEARCH      ANSWER
 â†“            â†“            â†“
        [ ANSWER NODE ]
             â†“
            END
```

---

# ðŸ§© FILE STRUCTURE

```
/lesson-13/
   â”œâ”€â”€ 13-multi-agent.js   â† main agent graph
   â”œâ”€â”€ scrape.js           â† Puppeteer scraper
   â””â”€â”€ .env                â† API keys
```

---

# ðŸ§  FULL BLOCK-BY-BLOCK EXPLANATION (MAIN FILE)

---

## ðŸŸ¦ **1. Imports + dotenv**

```js
import { config } from "dotenv";
config();

import readline from "readline";
import { ChatOpenAI } from "@langchain/openai";
import { StateGraph, START, END } from "@langchain/langgraph";
import { z } from "zod";
import { scrapeReact } from "./scrape.js";
```

### âœ” What this does
- Loads env variables  
- Imports LLM  
- Imports LangGraph  
- Imports Zod for schemas  
- Imports Puppeteer scraper  

---

## ðŸŸ¦ **2. Ensure API Keys**

```js
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const TAVILY_API_KEY = process.env.TAVILY_API_KEY;
```

If missing â†’ clean error.

---

## ðŸŸ¦ **3. Create the Model**

```js
const model = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
  apiKey: OPENAI_API_KEY,
});
```

### âœ” Why GPT-4o-mini?
- Deterministic
- Cheap
- Perfect for routing
- Strong reasoning
- Stable for production agents

---

## ðŸŸ¦ **4. Zod Message Schema**

```js
const MessageSchema = z.object({
  role: z.enum(["user", "assistant", "system"]),
  content: z.string(),
});

const State = z.object({
  messages: z.array(MessageSchema),
});
```

### âœ” Why Zod?
To prevent:

- malformed messages  
- missing roles  
- broken state updates  

Real agents MUST be safe.

---

## ðŸŸ¦ **5. Utility: Find Last User Message**

```js
function findLastUserMessage(state) {
  return [...state.messages].reverse().find((m) => m.role === "user");
}
```

Simple helper.  
Used in **every node**.

---

## ðŸŸ¦ **6. Tavily Search Node**

```js
async function tavilySearch(query) {
  if (!TAVILY_API_KEY) return "NO_TAVILY_KEY";
  try {
    const res = await fetch("https://api.tavily.com/search", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        api_key: TAVILY_API_KEY,
        query,
        search_depth: "advanced",
        include_answer: true,
      }),
    });
    const json = await res.json();
    return JSON.stringify(json);
  } catch (err) {
    return "SEARCH_ERROR_" + (err.message || String(err));
  }
}
```

### âœ” Why Tavily?
- Real-time search  
- Accurate result extraction  
- Designed for agents  

---

## ðŸŸ¦ **7. PLAN NODE â€” Hard Router + LLM Router**

```js
async function planNode(state) {
  const userMsg = findLastUserMessage(state)?.content || "";

  if (userMsg.match(/https?:\/\/\S+/i)) {
    return {
      messages: [...state.messages, { role: "system", content: "PLAN=scrape" }],
    };
  }

  const decisionResp = await model.invoke([
    {
      role: "system",
      content: `
You are a STRICT router. Output ONLY one word: "search" or "answer".
If the user asks anything recent like prices, days, current, etc â†’ "search".
Else â†’ "answer".
`,
    },
    ...state.messages,
  ]);

  const d = (decisionResp.content || "").toLowerCase().trim();
  const plan = d.includes("search") ? "search" : "answer";

  return {
    messages: [...state.messages, { role: "system", content: `PLAN=${plan}` }],
  };
}
```

### âœ” Why this router is powerful?
- If URL exists â†’ scrape  
- If question is about **today / now / recent** â†’ search  
- Else â†’ answer from memory  

This is EXACTLY how Perplexity routes tools.

---

## ðŸŸ¦ **8. SCRAPE NODE**

```js
async function scrapeNode(state) {
  const userMsg = findLastUserMessage(state)?.content || "";
  const urlMatch = userMsg.match(/https?:\/\/\S+/i);
  const url = urlMatch ? urlMatch[0] : null;
  if (!url) {
    return {
      messages: [...state.messages, { role: "system", content: "SCRAPED=NO_URL_PROVIDED" }],
    };
  }

  const scraped = await scrapeReact(url);
  return {
    messages: [...state.messages, { role: "system", content: `SCRAPED=${scraped}` }],
  };
}
```

### âœ” Uses real scraping (from scrape.js)

---

## ðŸŸ¦ **9. SEARCH NODE**

```js
async function searchNode(state) {
  const userMsg = findLastUserMessage(state)?.content || "";
  const q = userMsg || "";
  const result = await tavilySearch(q);
  return {
    messages: [...state.messages, { role: "system", content: `SEARCHED=${result}` }],
  };
}
```

---

## ðŸŸ¦ **10. ANSWER NODE**

```js
async function answerNode(state) {
  const scrapedEntry = state.messages.find((m) => m.content.startsWith("SCRAPED="));
  const searchedEntry = state.messages.find((m) => m.content.startsWith("SEARCHED="));
  const userMsg = findLastUserMessage(state)?.content || "";

  const prompt = `
IMPORTANT:
- Do NOT say "I cannot browse".
- Scraping/search was ALREADY done by your tools.
- Use provided scraped/search data ONLY.

User: ${userMsg}

Scraped: ${scrapedEntry ? scrapedEntry.content.replace(/^SCRAPED=/, "") : "NONE"}
Searched: ${searchedEntry ? searchedEntry.content.replace(/^SEARCHED=/, "") : "NONE"}

Give a concise final answer.
`;

  const out = await model.invoke([{ role: "user", content: prompt }]);
  return {
    messages: [...state.messages, { role: "assistant", content: out.content }],
  };
}
```

### âœ” Why this is powerful?
Stops LLM hallucination like:

- â€œI canâ€™t browseâ€
- â€œI donâ€™t know that dataâ€
- â€œI canâ€™t access internetâ€

---

# ðŸ§© EXPLAINING **scrape.js** (Block-by-Block)

---

## ðŸŸ¦ **1. Import puppeteer**

```js
import puppeteer from "puppeteer";
```

### âœ” Full browser control.

---

## ðŸŸ¦ **2. scrapeReact() function**

```js
export async function scrapeReact(url, { timeout = 30000 } = {}) {
  if (!url) return "NO_URL";

  let browser;
  try {
    browser = await puppeteer.launch({ headless: true });
    const page = await browser.newPage();
```

### âœ” Opens headless browser  
### âœ” Loads the page in full

---

## ðŸŸ¦ **3. Fake viewport + user-agent**

```js
    await page.setViewport({ width: 1280, height: 800 });
    await page.setUserAgent(
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)"
    );
```

### âœ” Pretend to be a real user  
### âœ” Helps avoid blocking

---

## ðŸŸ¦ **4. Navigate + wait**

```js
    await page.goto(url, { waitUntil: "networkidle2", timeout });
```

### âœ” Waits for JS-heavy sites  
### (React, Next.js, Vue, Angular)

---

## ðŸŸ¦ **5. Extract readable text**

```js
    const content = await page.evaluate(() => {
      return document.body.innerText || "";
    });
```

### âœ” Gets full text content  
### âœ” Works on ALL modern websites

---

## ðŸŸ¦ **6. Trim and slice**

```js
    return content.replace(/\s+/g, " ").trim().slice(0, 60_000);
```

### âœ” Output optimized for LLM input  
### âœ” Avoids huge tokens

---

## ðŸŸ¦ **7. Close the browser**

```js
  } finally {
    if (browser) await browser.close();
  }
}
```

---

# â–¶ï¸ HOW TO RUN

```
npm install
```

Add `.env`:

```
OPENAI_API_KEY=your_key
TAVILY_API_KEY=your_key
```

Run REPL:

```
node 13-multi-agent.js
```

---

# ðŸ§ª Example PROMPTS

```
> What is the price of Bitcoin today?
> Summarize https://webreal.in
> Who is the founder of OpenAI?
> Give me latest Google stock performance
```

---

# ðŸŽ‰ Final Notes

Lesson 13 is **production-level agent architecture**.

This is the SAME STRUCTURE used for:

- Perplexity  
- WebPilot  
- BrowserGPT  
- Research Agents  
- AI Assistants with Tools  
- Multi-Agent Supervisor Systems  

This is the future of MERN + AI + LangChain combined.

---
